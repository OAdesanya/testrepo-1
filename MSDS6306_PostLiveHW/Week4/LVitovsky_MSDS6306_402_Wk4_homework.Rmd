---
title: "LVitovsky_Week4_BootstrapHW"
author: "Vitovsky"
date: "June 4, 2016"
output:  
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Introduction
***The assignment instructed to create a total of four samples, two of different sizes from a normal distribution, and two of difference sizes from an exponential distribution.***

Groundwork used for this report:

  * a random normal distribution (x) of size 100, mean = 40, and standard deviation = 3
  
  * an exponential distribution (x2) of size 100 
  * sample sizes of 5 and 50 for each distribution
  
  * a Bias Corrected and accelerated bootstrap confidence interval to compare the confidence intervals calculated from the bootstrap techinque.
  
##Summary

Upon building and running the code, here were my observations:

**Sampling 50 and 5 from the normal distribution**

  * The bootstrap of the large and small samples generated a bootstrap mean of 40.51026 and 41.00502 respectively.  Both fell within their 95% confidence intervals (39.77734 - 40.85411 and 39.61505 - 40.95951, respectively), so if this were a test of actual data, I would not have rejected the null hypothesis.  There does not seem to be a statistical difference between the means of either sample and the population mean.
  
  * There was no change when finding the the Bias Corrected and accelerated Confidence Interval, which was found to be 39.81 - 40.81.  This indicates that there is no bias in our bootstrap confidence level.  Also, this is very close to the CIs of the two samples.  This is not surprising, as we took our samples from a randomized normal distribution.
  
  * The larger sample's standard deviation (3.0757) was larger than the smaller sample's standard deviation (2.408).  The standard deviation of the 100 random normal variables was 2.695.  
  
**Sampling 50 and 5 from the exponential distribution**

When running the same commands on an exponential distribution, here is what I found:

  * the bootstrapped means in these cases fell outside of the 95% confidence intervals.  The larger sample bootstrap mean of 0.83848 is below the confiendence interval of 0.84449 - 1.25168, and the smaller bootstrap mean of 2.35078 was above the 95% confidence interval of 0.854478 - 1.47757.  If I had collected these samples in an actual experiment, I would have rejected the null hypothesis.
  
  * after finding the Bias Corrected and accelerated bootstrap confidence interval, I found that there was a small difference between the 95% confidence interval and the BCa interval of the population.  It doesn't appear to be a large difference, though, and would have moved the confidence intervals positively.  This would not have helped the larger sample, which fell barely below the lower confidence interval, and the smaller sample, which was noticeably higher than the upper confidence interval.  The BCa does not change my interpretation that we would reject the null hypothese in this case.
  
  * after reviewing a stem and leaf chart of the exponential distribution, one can see why a random sample of 50 would be much more likely to include lower values than the smaller sample of size 5.  This shows how important it is to have as large of a sample as possible.
  
  * after running histograms of the large and small samples of the exponential distribution, one can see that the larger sample is approaching a normal distribution more closely than the small sample. Indeed, when I re-ran the exponential distribution samples, they approached a more normal distribution.
  
##Conclusion

Through bootstrapping, one can see that the Central Limit Theorem holds true.

  * As the sample size increased, the distribution of means converge upon being normal.
  
  * As the number of bootstraps increaes, the distribution of means converge upon being normal, regardless of the original distribution.  This supports the statement that one does not need to know that the original population is normally distributed.  This is why you collect a sufficient number of bootstrapped means.

  
### Coding / Supporting Documentation

Use a normal distribution with two different sample sizes and an exponential distribution with two different sample sizes

```{r RequiredPackages, include=FALSE}
library(boot)
```

```{r Bootstrap}
#created a normal distribution to choose samples from, placed inside "x"
#set.seed to reproduce results
set.seed(1)
x <- rnorm(100, 40, 3)

#create the bootstrap framework
xbar <- mean(x)
sem <- sd(x)/sqrt(100)
reps <- 1000
bootnorm <- numeric(reps)


#run a bootstrap sampling with a larger sample size
for(i in 1:reps) {
  bootsample <- sample(x, size = 50, replace = TRUE)
  samplemean <- mean(bootsample)
  samplesd <- sd(bootsample)
  tpivot <- (samplemean - xbar)/(samplesd/sqrt(50))
  bootnorm[i] <- tpivot
}

#find the quantiles to compute Confidence Intervals

quant <- quantile(bootnorm, c(0.025, 0.975))
quantlowend <- xbar - quant[2]*sem
quantupend <- xbar - quant[1]*sem
data.frame("SampleMean" = samplemean, "SampleSdDev" = samplesd, "XBar" = xbar, "LowerCI"=quantlowend, "UpperCI"=quantupend)
```

After running a sample size of 50, I then ran a sample size of 5.

``` {r SmallSampleBoot}

#run a bootstrap sampling with a small sample size
for(i in 1:reps) {
  bootsample <- sample(x, size = 5, replace = TRUE)
  samplemean <- mean(bootsample)
  samplesd <- sd(bootsample)
  tpivot <- (samplemean - xbar)/(samplesd/sqrt(5))
  bootnorm[i] <- tpivot
}

#find the quantiles to compute Confidence Intervals

quant <- quantile(bootnorm, c(0.025, 0.975))
quantlowend <- xbar - quant[2]*sem
quantupend <- xbar - quant[1]*sem
data.frame("SampleMean" = samplemean,"SampleSdDev" = samplesd, "XBar" = xbar, "LowerCI"=quantlowend, "UpperCI"=quantupend)
```

I then asked for the Bias Corrected Bootstrap CI's to test the validity of the bootstrap confidence intervals.

```{r BCa}
mymean <-function(d,i)
  mean(d[i])

myboot <- boot(x,mymean,R=1000)
boot.ci(myboot, type = c("perc", "bca"))

```

##Exponential Distribution

First, a larger sample of 50...

```{r ExpDistLarge}
#create exponential distribution
set.seed(2)
x2 <- rexp(100)

#create the bootstrap framework
xbar2 <- mean(x2)

#run a bootstrap sampling with a larger sample size
for(i in 1:reps) {
  bootsample <- sample(x2, size = 50, replace = TRUE)
  samplemean <- mean(bootsample)
  samplesd <- sd(bootsample)
  tpivot <- (samplemean - xbar2)/(samplesd/sqrt(50))
  bootnorm[i] <- tpivot
}

#view histogram of the results
hist(bootnorm, col = "light grey")
abline(v=mean(bootnorm), col = "blue")

#find the quantiles to compute Confidence Intervals

quant <- quantile(bootnorm, c(0.025, 0.975))
quantlowend <- xbar2 - quant[2]*sem
quantupend <- xbar2 - quant[1]*sem
data.frame("SampleMean" = samplemean, "SampleSdDev" = samplesd, "XBar" = xbar2, "LowerCI"=quantlowend, "UpperCI"=quantupend)

```

...then a smaller sample of 5

```{r ExpDistSmall}
#run a bootstrap sampling with a smaller sample size
for(i in 1:reps) {
  bootsample <- sample(x2, size = 5, replace = TRUE)
  samplemean <- mean(bootsample)
  samplesd <- sd(bootsample)
  tpivot <- (samplemean - xbar2)/(samplesd/sqrt(5))
  bootnorm[i] <- tpivot
}

#view a histogram of the results
hist(bootnorm, col = "light grey")
abline(v=mean(bootnorm), col = "blue")

#find the quantiles to compute Confidence Intervals

quant <- quantile(bootnorm, c(0.025, 0.975))
quantlowend <- xbar2 - quant[2]*sem
quantupend <- xbar2 - quant[1]*sem
data.frame("SampleMean" = samplemean, "SampleSdDev" = samplesd, "XBar" = xbar2, "LowerCI"=quantlowend, "UpperCI"=quantupend)

```

Ran a BCa command as before...

```{r BCa2}
mymean <-function(d,i)
  mean(d[i])

myboot <- boot(x2,mymean,R=1000)
boot.ci(myboot, type = c("perc", "bca"))

```

Created a stem and leaf plot to visualize the exponential distribution

```{r StemPlot}
stem(x2)
```

For the exponential distribution only, I increased the number of repetitions from 1,000 to 5,000 on the larger sample to see if the result would be closer to a normal distribution. The histogram is below.

```{r LargerBoot}
reps2 <- 5000
bootnorm <- numeric(reps2)

for(i in 1:reps2) {
  bootsample <- sample(x2, size = 50, replace = TRUE)
  samplemean <- mean(bootsample)
  samplesd <- sd(bootsample)
  tpivot <- (samplemean - xbar2)/(samplesd/sqrt(50))
  bootnorm[i] <- tpivot
}

#view histogram of the results
hist(bootnorm, col = "light grey")
abline(v=mean(bootnorm), col = "blue")

```


